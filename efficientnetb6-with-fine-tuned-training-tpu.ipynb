{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"! pip install -q efficientnet","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport json\nimport sys\nimport random\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow_probability as tfp\nimport tensorflow_addons as tfa\n\nimport albumentations\n\nimport re\nimport itertools\nimport joblib\nimport math\n\nfrom tensorflow import keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import (Input, MaxPooling2D, BatchNormalization,\n                                    GlobalAveragePooling2D, Dense, Conv2D,\n                                    Dropout, Flatten, Activation, ZeroPadding2D,\n                                    Add)\n\nfrom albumentations import (Compose, RandomBrightness, Normalize,\n                            HueSaturationValue, RandomContrast, \n                            HorizontalFlip,Rotate, CLAHE)\n\nfrom tensorflow.keras import activations\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import ReLU, concatenate\nimport tensorflow.keras.backend as K\n\nfrom keras.models import load_model\nfrom keras.utils import plot_model\nfrom tensorflow.keras.experimental import CosineDecay\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n\nimport efficientnet.tfkeras as efn\n\nfrom PIL import Image\nfrom functools import partial\nfrom kaggle_datasets import KaggleDatasets\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport gc\nimport tempfile","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GCS_DS_PATH = KaggleDatasets().get_gcs_path('ranzcr-clip-catheter-line-classification')\nGCS_DS_PATH","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"'gs://kds-949d43c601e22d0950846282da35581e051ced021a05ab31e0be609a'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() \n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","execution_count":4,"outputs":[{"output_type":"stream","text":"Running on TPU  grpc://10.0.0.2:8470\nREPLICAS:  8\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_SIZE = [528,528]\nHEIGHT,WIDTH = IMAGE_SIZE[0],IMAGE_SIZE[1]\nCHANNELS = 3\n\nAUTO = tf.data.experimental.AUTOTUNE\n\nFILENAMES = tf.io.gfile.glob(GCS_DS_PATH + '/train_tfrecords/*.tfrec')\nTRAINING_FILENAMES = FILENAMES[:-2]\nVALIDATION_FILENAMES = FILENAMES[-2:]\nTEST_FILENAMES = tf.io.gfile.glob(GCS_DS_PATH + '/test_tfrecords/*.tfrec')","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.image.resize(image, [*IMAGE_SIZE])\n    return image\n\n\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"StudyInstanceUID\"           : tf.io.FixedLenFeature([], tf.string),\n        \"image\"                      : tf.io.FixedLenFeature([], tf.string),\n        \"ETT - Abnormal\"             : tf.io.FixedLenFeature([], tf.int64), \n        \"ETT - Borderline\"           : tf.io.FixedLenFeature([], tf.int64), \n        \"ETT - Normal\"               : tf.io.FixedLenFeature([], tf.int64), \n        \"NGT - Abnormal\"             : tf.io.FixedLenFeature([], tf.int64), \n        \"NGT - Borderline\"           : tf.io.FixedLenFeature([], tf.int64), \n        \"NGT - Incompletely Imaged\"  : tf.io.FixedLenFeature([], tf.int64), \n        \"NGT - Normal\"               : tf.io.FixedLenFeature([], tf.int64), \n        \"CVC - Abnormal\"             : tf.io.FixedLenFeature([], tf.int64), \n        \"CVC - Borderline\"           : tf.io.FixedLenFeature([], tf.int64), \n        \"CVC - Normal\"               : tf.io.FixedLenFeature([], tf.int64), \n        \"Swan Ganz Catheter Present\" : tf.io.FixedLenFeature([], tf.int64),\n    }\n    \n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    label = [example['ETT - Abnormal'],\n                 example['ETT - Borderline'],\n                 example['ETT - Normal'],\n                 example['NGT - Abnormal'],\n                 example['NGT - Borderline'],\n                 example['NGT - Incompletely Imaged'],\n                 example['NGT - Normal'],\n                 example['CVC - Abnormal'],\n                 example['CVC - Borderline'],\n                 example['CVC - Normal'],\n                 example['Swan Ganz Catheter Present']]\n    label = [tf.cast(i,tf.float32) for i in label]\n    return image, label\n\n\ndef read_unlabeled_tfrecord(example):\n    UNLABELED_TFREC_FORMAT = {\n        \"StudyInstanceUID\"           : tf.io.FixedLenFeature([], tf.string),\n        \"image\"                      : tf.io.FixedLenFeature([], tf.string),\n    }\n    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    idnum = example['StudyInstanceUID']\n    return image, idnum\n\ndef load_dataset(filenames, labeled=True, ordered=False):\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False \n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) \n    dataset = dataset.with_options(ignore_order)\n    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n    return dataset","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@tf.function\ndef augment(image,label):\n    \n    img_size = [528,528]\n        \n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n\n    '''if tf.random.uniform([], 0, 1.0, dtype = tf.float32) > 0.75:\n        image = tf.image.transpose(image)\n\n    probablity_rotation = tf.random.uniform([], 0, 1.0, dtype = tf.float32)\n    if probablity_rotation > 0.75:\n        image = tf.image.rot90(image, k = 3)\n    elif probablity_rotation > 0.5:\n        image = tf.image.rot90(image, k = 2)\n    elif probablity_rotation > 0.25:\n        image = tf.image.rot90(image, k = 1)'''\n\n    if tf.random.uniform([], 0, 1.0, dtype = tf.float32) >= 0.4:\n        image = tf.image.random_saturation(image, lower = 0.8, upper = 1.2)\n    if tf.random.uniform([], 0, 1.0, dtype = tf.float32) >= 0.4:\n        image = tf.image.random_contrast(image, lower = 0.8, upper = 1.2)\n    if tf.random.uniform([], 0, 1.0, dtype = tf.float32) >= 0.4:\n        image = tf.image.random_brightness(image, max_delta = 0.1)\n\n    probability_cropping = tf.random.uniform([], 0, 1.0, dtype = tf.float32)\n    \n    if probability_cropping > 0.7:\n        if probability_cropping > 0.9:\n            image = tf.image.central_crop(image, central_fraction = 0.7)\n        elif probability_cropping > 0.8:\n            image = tf.image.central_crop(image, central_fraction = 0.8)\n        else:\n            image = tf.image.central_crop(image, central_fraction = 0.9)\n            \n    elif probability_cropping > 0.5:\n        crop_size = tf.random.uniform([], int(img_size[0] * 0.8), img_size[0], dtype = tf.int32)\n        image = tf.image.random_crop(image, size = [crop_size, crop_size, 3])\n\n    image = tf.image.resize(image, size = img_size)\n    image = tf.reshape(image, [*img_size, 3])\n        \n    return image,label\n\ndef get_training_dataset():\n    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n    dataset = dataset.map(augment, num_parallel_calls=AUTO)\n    dataset = dataset.repeat() \n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\ndef get_validation_dataset(ordered=False):\n    dataset = load_dataset(VALIDATION_FILENAMES, labeled=True, ordered=ordered)\n    dataset = dataset.map(augment, num_parallel_calls=AUTO)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\ndef get_test_dataset(ordered=False):\n    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n    dataset = dataset.map(augment, num_parallel_calls=AUTO)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\ndef count_data_items(filenames):\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)\n\nNUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\nNUM_VALIDATION_IMAGES = count_data_items(VALIDATION_FILENAMES)\nNUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\nprint('Dataset: {} training images, {} validation images, {} unlabeled test images'.format(NUM_TRAINING_IMAGES,\n                                                                                           NUM_VALIDATION_IMAGES,\n                                                                                           NUM_TEST_IMAGES))","execution_count":7,"outputs":[{"output_type":"stream","text":"Dataset: 26334 training images, 3762 validation images, 3584 unlabeled test images\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n\ntrain_ds = get_training_dataset()\nvalid_ds = get_validation_dataset()\ntest_ds = get_test_dataset()\n\nprint(\"Training:\", train_ds)\nprint(\"Validation:\",valid_ds)\nprint(\"Test:\", test_ds)","execution_count":8,"outputs":[{"output_type":"stream","text":"Training: <PrefetchDataset shapes: ((None, 528, 528, 3), (None, 11)), types: (tf.float32, tf.float32)>\nValidation: <PrefetchDataset shapes: ((None, 528, 528, 3), (None, 11)), types: (tf.float32, tf.float32)>\nTest: <PrefetchDataset shapes: ((None, 528, 528, 3), (None,)), types: (tf.float32, tf.string)>\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model():\n    \n    #inputs = tf.keras.Input(shape=(600,600,3))\n    \n    model = tf.keras.Sequential()\n    base_model = efn.EfficientNetB6(\n            input_shape=(528,528,3),\n            weights='imagenet',\n            include_top=False)\n    \n    for layer in base_model.layers:\n        if not isinstance(layer,BatchNormalization):\n            layer.trainable = True           \n    \n    '''x = tf.keras.applications.InceptionV3(\n            input_shape=(512,512,3),\n            weights='imagenet',\n            include_top=False)(inputs)'''\n    \n    model.add(base_model)\n    model.add(tf.keras.layers.GaussianNoise(1))\n    model.add(GlobalAveragePooling2D())\n    #model.add(Dropout(0.5))\n    \n    '''model.add(Dense(512,activation=tf.keras.layers.LeakyReLU(alpha=0.2)))\n    model.add(BatchNormalization())\n    model.add(Dense(256,activation=tf.keras.layers.LeakyReLU(alpha=0.2)))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    model.add(Dense(128,activation=tf.keras.layers.LeakyReLU(alpha=0.2)))\n    model.add(BatchNormalization())'''\n    \n    model.add(Dense(11,activation=\"sigmoid\"))\n\n    return model","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = create_model()\nmodel.summary()","execution_count":10,"outputs":[{"output_type":"stream","text":"Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b6_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n165527552/165527152 [==============================] - 5s 0us/step\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nefficientnet-b6 (Functional) (None, 17, 17, 2304)      40960136  \n_________________________________________________________________\ngaussian_noise (GaussianNois (None, 17, 17, 2304)      0         \n_________________________________________________________________\nglobal_average_pooling2d (Gl (None, 2304)              0         \n_________________________________________________________________\ndense (Dense)                (None, 11)                25355     \n=================================================================\nTotal params: 40,985,491\nTrainable params: 40,761,059\nNon-trainable params: 224,432\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sigmoid_focal_crossentropy(y_true, y_pred, alpha=0.25, gamma=2.0):\n    \n    def smooth(y, smooth_factor):\n        assert len(y.shape) == 2\n        y *= 1 - smooth_factor\n        y += smooth_factor / y.shape[1]\n        return y\n    \n    #label smoothing factor\n    FACTOR = 0.1\n    alpha_factor = 1.0\n    modulating_factor = 1.0\n\n    y_pred = tf.convert_to_tensor(y_pred)\n    y_true = tf.convert_to_tensor(smooth(y_true, FACTOR), dtype=y_pred.dtype)\n\n    ce = K.binary_crossentropy(y_true, y_pred, from_logits=False)\n\n    p_t = (y_true * y_pred) + ((1 - y_true) * (1 - y_pred))\n    \n    alpha = tf.convert_to_tensor(alpha, dtype=K.floatx())\n    alpha_factor = y_true * alpha + (1 - y_true) * (1 - alpha)\n\n    gamma = tf.convert_to_tensor(gamma, dtype=K.floatx())\n    modulating_factor = tf.pow((1.0 - p_t), gamma)\n\n    return tf.reduce_sum(alpha_factor * modulating_factor * ce, axis=-1)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS=40\ndef lrfn(epoch, bs=BATCH_SIZE, epochs=40):\n\n    LR_START = 1e-6\n    LR_MAX = 2e-4\n    LR_FINAL = 1e-6\n    LR_RAMPUP_EPOCHS = 4\n    LR_SUSTAIN_EPOCHS = 0\n    DECAY_EPOCHS = epochs  - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS - 1\n    LR_EXP_DECAY = (LR_FINAL / LR_MAX) ** (1 / (EPOCHS - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS - 1))\n\n    if epoch < LR_RAMPUP_EPOCHS:\n        lr = LR_START + (LR_MAX + LR_START) * (epoch / LR_RAMPUP_EPOCHS) ** 2.5\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX\n    else:\n        epoch_diff = epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS\n        decay_factor = (epoch_diff / DECAY_EPOCHS) * math.pi\n        decay_factor= (tf.math.cos(decay_factor).numpy() + 1) / 2        \n        lr = LR_FINAL + (LR_MAX - LR_FINAL) * decay_factor\n\n    return lr\n\nimport matplotlib.pyplot as plt  \nrng = [i for i in range(EPOCHS)]\ny = [lrfn(x) for x in rng]\nplt.plot(rng, y)","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"[<matplotlib.lines.Line2D at 0x7fc4b033cad0>]"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_callbacks(model_save_path):\n    \n    \n    if not os.path.exists(model_save_path):\n        os.makedirs(model_save_path)\n    \n    cpk_path = f'{model_save_path}/model.h5'\n\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        filepath=cpk_path,\n        monitor='val_auc',\n        mode='max',\n        save_best_only=True,\n        verbose=1\n    )\n\n    reducelr = tf.keras.callbacks.ReduceLROnPlateau(\n        monitor='val_auc',\n        mode='max',\n        factor=0.7,\n        patience=5,\n        verbose=1\n    )\n    \n    #lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: lrfn(epoch), verbose=1)\n\n    earlystop = tf.keras.callbacks.EarlyStopping(\n        monitor='val_auc',\n        mode='max',\n        patience=10, \n        verbose=1\n    )\n    \n    callbacks = [checkpoint,reducelr, earlystop]\n    return callbacks","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS= 40\nVERBOSE =1\nMODEL_PATH = '.'\nSTEPS_PER_EPOCH = NUM_TRAINING_IMAGES//(BATCH_SIZE)\n\nwith strategy.scope():\n    \n    model = create_model()\n    \n    opt = keras.optimizers.Adam()\n    #opt = tfa.optimizers.RectifiedAdam(lr=1e-3,total_steps=50,\n                                       #warmup_proportion=0.2,min_lr=1e-4)\n    #opt = tfa.optimizers.MovingAverage(opt)    \n    \n    #loss=tfa.losses.SigmoidFocalCrossEntropy()\n    \n    model.compile(loss=tf.keras.losses.BinaryCrossentropy(), \n                  optimizer=opt, \n                 metrics = [tf.keras.metrics.AUC(name='auc',multi_label=True)])\n    \n    callbacks = create_callbacks(MODEL_PATH)\n    \n    history = model.fit(train_ds, \n                        epochs=EPOCHS,\n                        callbacks=callbacks,\n                        validation_data = valid_ds,\n                        steps_per_epoch = STEPS_PER_EPOCH,\n                        verbose=VERBOSE)    ","execution_count":14,"outputs":[{"output_type":"stream","text":"Epoch 1/40\n205/205 [==============================] - 385s 1s/step - loss: 0.2786 - auc: 0.7154 - val_loss: 0.3618 - val_auc: 0.7409\n\nEpoch 00001: val_auc improved from -inf to 0.74092, saving model to ./model.h5\nEpoch 2/40\n205/205 [==============================] - 201s 982ms/step - loss: 0.2007 - auc: 0.8318 - val_loss: 0.2291 - val_auc: 0.8416\n\nEpoch 00002: val_auc improved from 0.74092 to 0.84159, saving model to ./model.h5\nEpoch 3/40\n205/205 [==============================] - 201s 982ms/step - loss: 0.1764 - auc: 0.8865 - val_loss: 0.2069 - val_auc: 0.8843\n\nEpoch 00003: val_auc improved from 0.84159 to 0.88433, saving model to ./model.h5\nEpoch 4/40\n205/205 [==============================] - 202s 986ms/step - loss: 0.1628 - auc: 0.9087 - val_loss: 0.1991 - val_auc: 0.8870\n\nEpoch 00004: val_auc improved from 0.88433 to 0.88701, saving model to ./model.h5\nEpoch 5/40\n205/205 [==============================] - 201s 983ms/step - loss: 0.1547 - auc: 0.9105 - val_loss: 0.1971 - val_auc: 0.9067\n\nEpoch 00005: val_auc improved from 0.88701 to 0.90669, saving model to ./model.h5\nEpoch 6/40\n205/205 [==============================] - 202s 988ms/step - loss: 0.1466 - auc: 0.9231 - val_loss: 0.1989 - val_auc: 0.9032\n\nEpoch 00006: val_auc did not improve from 0.90669\nEpoch 7/40\n205/205 [==============================] - 202s 984ms/step - loss: 0.1415 - auc: 0.9260 - val_loss: 0.1753 - val_auc: 0.9154\n\nEpoch 00007: val_auc improved from 0.90669 to 0.91544, saving model to ./model.h5\nEpoch 8/40\n205/205 [==============================] - 201s 982ms/step - loss: 0.1372 - auc: 0.9341 - val_loss: 0.1789 - val_auc: 0.9162\n\nEpoch 00008: val_auc improved from 0.91544 to 0.91620, saving model to ./model.h5\nEpoch 9/40\n205/205 [==============================] - 202s 984ms/step - loss: 0.1326 - auc: 0.9262 - val_loss: 0.1743 - val_auc: 0.9273\n\nEpoch 00009: val_auc improved from 0.91620 to 0.92732, saving model to ./model.h5\nEpoch 10/40\n205/205 [==============================] - 202s 987ms/step - loss: 0.1288 - auc: 0.9445 - val_loss: 0.1753 - val_auc: 0.9216\n\nEpoch 00010: val_auc did not improve from 0.92732\nEpoch 11/40\n205/205 [==============================] - 202s 985ms/step - loss: 0.1259 - auc: 0.9419 - val_loss: 0.1716 - val_auc: 0.9335\n\nEpoch 00011: val_auc improved from 0.92732 to 0.93345, saving model to ./model.h5\nEpoch 12/40\n205/205 [==============================] - 202s 985ms/step - loss: 0.1234 - auc: 0.9521 - val_loss: 0.1687 - val_auc: 0.9233\n\nEpoch 00012: val_auc did not improve from 0.93345\nEpoch 13/40\n205/205 [==============================] - 202s 987ms/step - loss: 0.1176 - auc: 0.9517 - val_loss: 0.1697 - val_auc: 0.9266\n\nEpoch 00013: val_auc did not improve from 0.93345\nEpoch 14/40\n205/205 [==============================] - 202s 985ms/step - loss: 0.1169 - auc: 0.9517 - val_loss: 0.1703 - val_auc: 0.9235\n\nEpoch 00014: val_auc did not improve from 0.93345\nEpoch 15/40\n205/205 [==============================] - 202s 986ms/step - loss: 0.1134 - auc: 0.9621 - val_loss: 0.1722 - val_auc: 0.9171\n\nEpoch 00015: val_auc did not improve from 0.93345\nEpoch 16/40\n205/205 [==============================] - 203s 992ms/step - loss: 0.1093 - auc: 0.9623 - val_loss: 0.1801 - val_auc: 0.9119\n\nEpoch 00016: val_auc did not improve from 0.93345\n\nEpoch 00016: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\nEpoch 17/40\n205/205 [==============================] - 202s 987ms/step - loss: 0.1019 - auc: 0.9650 - val_loss: 0.1754 - val_auc: 0.9226\n\nEpoch 00017: val_auc did not improve from 0.93345\nEpoch 18/40\n205/205 [==============================] - 202s 985ms/step - loss: 0.0956 - auc: 0.9671 - val_loss: 0.1719 - val_auc: 0.9171\n\nEpoch 00018: val_auc did not improve from 0.93345\nEpoch 19/40\n205/205 [==============================] - 202s 986ms/step - loss: 0.0916 - auc: 0.9719 - val_loss: 0.1783 - val_auc: 0.9086\n\nEpoch 00019: val_auc did not improve from 0.93345\nEpoch 20/40\n205/205 [==============================] - 202s 986ms/step - loss: 0.0869 - auc: 0.9753 - val_loss: 0.1889 - val_auc: 0.9170\n\nEpoch 00020: val_auc did not improve from 0.93345\nEpoch 21/40\n205/205 [==============================] - 202s 984ms/step - loss: 0.0837 - auc: 0.9785 - val_loss: 0.1885 - val_auc: 0.9093\n\nEpoch 00021: val_auc did not improve from 0.93345\n\nEpoch 00021: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\nEpoch 00021: early stopping\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_name = \"EfficientNetB6_FineTuned.h5\"\nmodel.save(model_name)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}